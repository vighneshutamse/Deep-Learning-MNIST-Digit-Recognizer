{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hejgZ6TnkKMh"
   },
   "source": [
    "## <center> D19037 - Vighnesh Tamse - Digit Recognizer for MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "za12b8bv1gWr"
   },
   "source": [
    "### Objective :\n",
    "To build a Feed Forward Network for MNIST Classification in Pytorch in not more than 10 epochs.\n",
    "\n",
    "### Parameters :\n",
    "1. Number of parameters used in the model ( lower the better)\n",
    "2. Validation data accuracy (higher the better)\n",
    "3. Experimentation details to reach at the final set of parameters used in the model.\n",
    "4. Uploading your code on your github profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKXMiIh66xXZ"
   },
   "source": [
    "***Importing necessary libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqc5qpRp_fVY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reading the MNIST data and splitting into train and test data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsTRVnem_gGX"
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',train=True,transform=transform,download=True)\n",
    "testset=datasets.MNIST('~/.pytorch/MNIST_data/',train=False,transform=transform,download=True)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=256,shuffle=True,num_workers=0)\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=256,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creating a Feed Forward Network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zr96eKLL_gIv"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "\n",
    "#Adam - adaptive learning rate optimization algorithm\n",
    "optimizer=optim.SGD(model.parameters(),lr=1e-2,weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "'''Using the Negative Log Likelihood loss function to define how well your neural network classifies data.\n",
    "The negative log-likelihood function is defined as loss=-log(y) and produces a high value when the values of the output layer \n",
    "are evenly distributed and low. In other words, there's a high loss when the classification is unclear.'''\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Calculating train and test loss for each forward propagation for each batch size, and then back propagating to minimize the loss. This is repeated until all the data has been covered which constitutes to 1 epoch.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "XWby6Tll_gNZ",
    "outputId": "8ee0e629-f0d6-4a9d-9625-c60b6f447224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 0.035..  Test Loss: 0.068..  Test Accuracy: 0.982\n",
      "Epoch: 2/10..  Training Loss: 0.034..  Test Loss: 0.069..  Test Accuracy: 0.981\n",
      "Epoch: 3/10..  Training Loss: 0.033..  Test Loss: 0.074..  Test Accuracy: 0.981\n",
      "Epoch: 4/10..  Training Loss: 0.030..  Test Loss: 0.071..  Test Accuracy: 0.982\n",
      "Epoch: 5/10..  Training Loss: 0.031..  Test Loss: 0.072..  Test Accuracy: 0.982\n",
      "Epoch: 6/10..  Training Loss: 0.028..  Test Loss: 0.075..  Test Accuracy: 0.982\n",
      "Epoch: 7/10..  Training Loss: 0.027..  Test Loss: 0.072..  Test Accuracy: 0.982\n",
      "Epoch: 8/10..  Training Loss: 0.025..  Test Loss: 0.075..  Test Accuracy: 0.981\n",
      "Epoch: 9/10..  Training Loss: 0.026..  Test Loss: 0.068..  Test Accuracy: 0.984\n",
      "Epoch: 10/10..  Training Loss: 0.026..  Test Loss: 0.067..  Test Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels) # a single value for ex 2.33\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.shape[0] ## (2.33*64 + 2.22*64 + 2.12*33) / 138 \n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels) *images.shape[0]\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.sum(equals).item()\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader.dataset))\n",
    "        test_losses.append(test_loss.item()/len(testloader.dataset))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader.dataset)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader.dataset)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader.dataset)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking whether the predicted value is same as actual value.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "fWlgY0dQRjoE",
    "outputId": "89afcc93-de13-4c5f-96a5-e18922185160"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           4       4\n",
       "1           0       0\n",
       "2           1       1\n",
       "3           2       2\n",
       "4           9       9\n",
       "5           8       8\n",
       "6           2       2\n",
       "7           6       6\n",
       "8           9       9\n",
       "9           9       9\n",
       "10          2       2\n",
       "11          3       3\n",
       "12          0       0\n",
       "13          3       3\n",
       "14          1       1\n",
       "15          1       1"
      ]
     },
     "execution_count": 206,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Predicted\":top_class.view(top_class.shape[0]),\"Actual\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "t8juECx8Kzda",
    "outputId": "4701a61b-7d07-4bb6-e2c4-3c5be9d9bc39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plotting the training and validation loss curves.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "1u7w4sbf_gXL",
    "outputId": "03d788dd-d166-422e-fd69-570f2ee07162"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbf999484e0>"
      ]
     },
     "execution_count": 208,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjAKehFRAJOQS8iEnAKehGRgPv/8b37i6Dq/KsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G9XhmwwX_gaC",
    "outputId": "5e2d8198-77e8-4d3a-a25a-00d1d5cac237"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, tensor(3))"
      ]
     },
     "execution_count": 209,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_class.item(),labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing the state of the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "9cvIf59D_geP",
    "outputId": "4cf8a7e5-266c-4338-f63a-bc9cf78ef663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([256, 784])\n",
      "fc1.bias \t torch.Size([256])\n",
      "fc2.weight \t torch.Size([128, 256])\n",
      "fc2.bias \t torch.Size([128])\n",
      "fc3.weight \t torch.Size([64, 128])\n",
      "fc3.bias \t torch.Size([64])\n",
      "fc4.weight \t torch.Size([10, 64])\n",
      "fc4.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing the state of the optimizer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vnwDWIdn_giF",
    "outputId": "71d731f2-a04d-4ccf-b421-d56976f984ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {140460888812928: {'momentum_buffer': tensor([[-2.2991e-07,  2.2155e-07,  3.2681e-07,  ..., -2.4464e-07,\n",
      "          3.3687e-07,  2.9705e-07],\n",
      "        [ 3.1012e-07,  2.8412e-07,  2.9594e-07,  ..., -7.4846e-08,\n",
      "          1.7701e-07,  2.3206e-08],\n",
      "        [-2.9963e-07,  2.1111e-07,  2.5997e-07,  ...,  5.2695e-08,\n",
      "         -2.5856e-07, -2.4651e-07],\n",
      "        ...,\n",
      "        [-1.3282e-07, -7.3023e-08, -1.7630e-07,  ..., -2.7354e-07,\n",
      "         -3.3733e-07, -5.2316e-09],\n",
      "        [ 2.7173e-07,  3.1839e-07,  3.5619e-07,  ..., -8.4232e-09,\n",
      "         -2.6176e-08, -3.3377e-07],\n",
      "        [ 1.6045e-07, -3.1025e-07,  7.9105e-08,  ...,  3.2183e-07,\n",
      "         -2.3738e-07, -7.1490e-09]])}, 140460888730216: {'momentum_buffer': tensor([-3.2325e-03,  2.5778e-03,  4.8344e-02, -4.1885e-03,  3.1665e-03,\n",
      "        -2.3131e-03, -3.2891e-03,  1.9298e-03, -4.5489e-04, -1.6295e-02,\n",
      "         7.4755e-04,  1.6886e-03,  1.1619e-02,  1.0836e-02,  3.3721e-03,\n",
      "         7.2863e-03, -3.8732e-02, -3.0947e-03,  2.5493e-03,  4.1259e-03,\n",
      "        -1.7836e-02, -1.9870e-02,  1.3269e-02, -6.3058e-05, -2.4956e-03,\n",
      "        -2.5436e-03,  9.7845e-03,  9.0149e-03, -2.4876e-02,  9.7087e-03,\n",
      "         3.6310e-03,  4.6416e-02, -1.2677e-02, -3.7477e-03,  2.4044e-02,\n",
      "        -9.3825e-05,  1.6581e-03, -1.5853e-02,  1.3153e-03, -4.3315e-03,\n",
      "        -1.2756e-02,  3.1828e-03,  2.4808e-02, -8.6445e-03, -8.0628e-03,\n",
      "         3.7151e-03, -4.8501e-04,  3.5960e-02,  4.6437e-03, -6.4127e-03,\n",
      "         3.7125e-02, -2.8692e-03, -3.2441e-02, -5.2941e-03,  1.4378e-03,\n",
      "         1.8754e-03, -2.7902e-03,  3.9429e-02,  2.0474e-03, -1.9039e-02,\n",
      "        -5.1458e-03, -1.3085e-03, -2.6865e-02, -2.5810e-03,  1.1739e-02,\n",
      "        -3.7642e-02,  1.0529e-05, -5.1504e-03, -7.7660e-03,  1.0748e-02,\n",
      "        -1.6703e-02, -6.4931e-03,  3.8643e-03, -1.0522e-03, -2.8203e-02,\n",
      "         1.1892e-02, -7.0827e-03, -1.4067e-02,  2.8446e-02,  2.6809e-02,\n",
      "         1.8420e-03, -1.6441e-03, -2.8032e-03, -2.1567e-04,  6.8357e-03,\n",
      "        -4.5369e-02,  8.9245e-04,  3.7369e-02, -2.2827e-02, -4.3048e-03,\n",
      "        -4.7054e-03,  5.0740e-03, -1.5509e-04,  2.4045e-03, -1.7410e-02,\n",
      "        -9.6764e-03, -3.0692e-04, -3.9947e-02, -2.9143e-03, -7.2075e-03,\n",
      "        -4.8940e-03, -1.1040e-02,  2.5387e-03, -1.0489e-02, -1.1090e-02,\n",
      "         5.2303e-02, -8.9987e-03, -5.1842e-06, -3.6399e-03,  1.4547e-02,\n",
      "         8.4138e-04,  1.2022e-02, -2.9709e-04,  1.1958e-02, -7.3087e-03,\n",
      "        -2.0707e-02, -4.1816e-03, -4.4728e-03,  6.9196e-03, -2.6677e-02,\n",
      "        -8.6604e-03, -2.2754e-02,  4.1531e-02,  2.1487e-03, -5.1122e-04,\n",
      "        -5.9279e-03,  1.6484e-02,  3.0046e-02,  1.3699e-03,  2.0805e-02,\n",
      "        -6.0877e-03,  1.7768e-03,  2.1518e-03, -1.4965e-03, -1.4308e-02,\n",
      "        -8.5349e-03,  2.0283e-02,  1.6060e-02,  1.1376e-02,  1.3165e-03,\n",
      "         3.7107e-02, -1.6107e-02, -3.7601e-03,  1.8952e-02, -1.5195e-02,\n",
      "        -7.3548e-03,  1.6351e-03,  2.0275e-02,  2.1034e-02, -5.9040e-03,\n",
      "        -3.1772e-02, -2.0590e-03, -1.8446e-02,  4.1745e-02,  1.1020e-02,\n",
      "         1.1687e-04, -2.1361e-02,  3.2297e-03,  1.6631e-02,  5.6813e-03,\n",
      "        -2.2630e-03, -3.0629e-03,  2.4419e-04, -3.3416e-03,  1.7045e-02,\n",
      "         9.1002e-03, -8.5352e-03,  5.0252e-02, -4.0171e-03,  2.1895e-02,\n",
      "         6.8470e-03, -1.5084e-03, -2.5237e-03,  4.8281e-04, -1.3593e-02,\n",
      "        -6.8821e-05,  1.1094e-02, -1.0794e-03, -7.5754e-04,  2.4279e-03,\n",
      "        -4.6842e-03, -6.4063e-03,  1.0109e-02,  1.4602e-02,  4.7124e-03,\n",
      "        -4.7968e-03, -2.5704e-03, -2.2338e-03,  1.0153e-02,  6.0790e-03,\n",
      "        -3.4090e-02, -5.3517e-04, -8.7895e-04,  4.3530e-02, -6.3107e-03,\n",
      "         3.2565e-02,  2.2339e-03, -4.5051e-04, -5.4471e-04,  2.9094e-02,\n",
      "        -1.0710e-03, -7.0161e-03,  4.2199e-03,  5.4783e-03,  1.7726e-03,\n",
      "         5.6869e-03,  1.6278e-02, -1.5665e-02,  2.4240e-02, -9.1255e-05,\n",
      "         5.8698e-03, -1.3610e-04,  7.2801e-03, -3.5664e-02, -1.0951e-03,\n",
      "        -2.2430e-03, -8.4432e-03,  1.3792e-02, -2.2858e-04,  5.4969e-04,\n",
      "         2.4194e-02,  2.9584e-03,  2.4799e-03, -1.0895e-02,  2.4709e-02,\n",
      "         2.4312e-04, -1.9022e-03,  1.0472e-03, -2.7373e-03, -3.4512e-04,\n",
      "        -1.4620e-03,  1.8475e-02,  3.8329e-02,  7.8252e-03, -3.0031e-03,\n",
      "         3.0914e-03, -1.3693e-02, -4.4446e-03, -2.0270e-02,  2.3394e-02,\n",
      "         2.1329e-02, -4.2582e-03, -1.5674e-02, -4.7191e-02,  9.6231e-03,\n",
      "        -1.4810e-03, -2.5837e-03, -2.6940e-02,  9.4054e-03,  3.4329e-02,\n",
      "        -4.6333e-03, -6.9729e-03, -3.8381e-03, -5.1878e-03, -9.9380e-03,\n",
      "        -1.0864e-02])}, 140460888730072: {'momentum_buffer': tensor([[-5.9550e-04,  1.4174e-04, -4.2006e-04,  ...,  3.1837e-03,\n",
      "          5.0780e-03,  5.9561e-04],\n",
      "        [ 8.0398e-05, -5.3383e-05, -4.2549e-04,  ..., -8.3729e-04,\n",
      "         -6.5800e-04,  1.0392e-03],\n",
      "        [-1.8831e-03,  2.0978e-04, -1.2093e-04,  ..., -8.0398e-04,\n",
      "         -4.6186e-04, -3.4182e-04],\n",
      "        ...,\n",
      "        [ 1.4430e-04, -2.1707e-05, -2.3971e-03,  ...,  1.5251e-05,\n",
      "         -3.9743e-03, -7.5255e-03],\n",
      "        [ 1.0080e-02,  1.6728e-04,  3.4330e-04,  ...,  7.3020e-05,\n",
      "          4.0033e-03, -4.0024e-04],\n",
      "        [-1.0021e-02,  2.3447e-04, -3.2816e-04,  ..., -3.9002e-04,\n",
      "         -5.4590e-03, -7.6175e-04]])}, 140460908412360: {'momentum_buffer': tensor([-2.2205e-03, -1.3548e-02, -2.0389e-02, -2.1321e-04,  1.9988e-02,\n",
      "         1.5703e-03, -3.1201e-03,  6.7315e-04,  9.9381e-03, -1.9661e-04,\n",
      "        -2.6196e-02, -8.3496e-03,  3.3229e-03, -1.9551e-02, -2.4613e-02,\n",
      "         1.7774e-02, -7.4831e-03, -8.2595e-03,  4.9495e-04,  9.3191e-03,\n",
      "        -5.3640e-03,  3.0624e-02,  1.6337e-02, -1.7894e-03, -4.0545e-03,\n",
      "         4.0127e-03, -2.1781e-02, -2.2148e-02, -9.9968e-03, -7.9926e-04,\n",
      "         2.9212e-02,  1.2182e-02,  5.5308e-04,  2.4481e-02,  2.0352e-03,\n",
      "        -3.5070e-03,  1.3433e-02,  5.3049e-03,  1.6226e-03, -1.8478e-03,\n",
      "         1.0500e-03,  3.9803e-02, -5.8354e-03,  1.5711e-03,  1.3431e-02,\n",
      "        -1.1024e-02,  5.8369e-03,  1.0063e-02, -2.7099e-02,  2.0643e-02,\n",
      "         4.5109e-03, -1.1045e-02,  1.2173e-02,  9.8057e-03,  9.3200e-03,\n",
      "        -1.9630e-03,  7.4353e-03,  7.8182e-03,  2.0331e-02, -2.3340e-02,\n",
      "        -2.5680e-02, -1.1911e-02, -2.9443e-02,  2.1476e-02,  2.1862e-03,\n",
      "        -4.6812e-04, -1.4811e-03, -1.8855e-04,  1.7802e-02,  8.1776e-03,\n",
      "         2.3980e-02,  8.2982e-03, -1.4253e-02,  1.4836e-02, -1.2759e-02,\n",
      "         8.6559e-03, -1.6592e-02, -1.9164e-02,  9.2551e-03, -3.8377e-04,\n",
      "        -2.5281e-02,  1.3918e-02, -2.4525e-02, -7.3219e-04, -2.6839e-02,\n",
      "        -2.7121e-02,  3.7941e-02, -5.7413e-03,  3.1505e-02,  3.1253e-03,\n",
      "         2.5888e-02,  8.1011e-03,  2.4743e-02,  3.8063e-02,  6.3508e-03,\n",
      "        -3.4572e-03, -2.8684e-03, -2.9834e-02,  4.9908e-03, -1.5245e-02,\n",
      "        -1.4219e-02,  9.2973e-03,  2.1983e-02,  8.1800e-03, -5.3839e-02,\n",
      "        -1.1338e-02,  2.1330e-03,  5.6489e-03,  4.1331e-02, -6.3010e-04,\n",
      "         1.1016e-02,  4.8160e-05, -4.1324e-03,  3.5106e-02, -2.6213e-02,\n",
      "        -2.4130e-02, -1.0133e-02, -8.2403e-03,  2.9608e-03, -6.2718e-03,\n",
      "         1.5723e-02,  6.0458e-03,  1.6032e-02, -1.0927e-02,  8.7533e-04,\n",
      "        -1.3386e-02,  3.2605e-03, -2.8099e-02])}, 140460892820392: {'momentum_buffer': tensor([[-1.3296e-03, -1.2984e-03, -1.1802e-03,  ..., -7.5822e-04,\n",
      "         -6.9592e-04, -1.5689e-03],\n",
      "        [ 1.0827e-02, -1.6598e-03,  5.2845e-03,  ...,  6.0893e-04,\n",
      "         -3.0681e-04,  6.6066e-03],\n",
      "        [ 8.5042e-04,  3.5078e-04, -2.0556e-03,  ..., -5.2830e-03,\n",
      "         -8.1405e-03,  4.9002e-04],\n",
      "        ...,\n",
      "        [ 8.4147e-03,  2.1141e-04,  4.6683e-03,  ..., -2.3150e-04,\n",
      "         -2.2712e-03,  4.7024e-03],\n",
      "        [-6.0768e-03, -2.5340e-04, -5.5775e-03,  ...,  2.3372e-05,\n",
      "         -9.8889e-04, -9.7889e-03],\n",
      "        [-6.7295e-03,  1.0190e-03, -4.1681e-03,  ..., -5.6748e-03,\n",
      "         -8.8359e-03, -4.7153e-03]])}, 140460888797328: {'momentum_buffer': tensor([-5.1214e-03,  1.8404e-02, -1.3297e-02,  3.2372e-04,  7.5317e-03,\n",
      "        -7.4767e-03,  7.1714e-04, -2.6848e-02, -9.5632e-03,  1.6220e-03,\n",
      "         5.5357e-03,  4.5181e-04, -4.5227e-03,  2.2233e-03, -1.9803e-03,\n",
      "        -2.2162e-02,  1.6031e-03, -3.1591e-03, -2.1405e-03, -1.0914e-02,\n",
      "        -1.9079e-03, -4.9759e-03, -1.9252e-02, -5.1353e-03,  2.6067e-02,\n",
      "         1.2479e-02, -3.0481e-03,  7.3393e-03, -3.1906e-03,  5.2929e-03,\n",
      "        -8.8485e-04, -1.2804e-02, -7.0467e-03,  3.4651e-05, -6.3549e-03,\n",
      "         1.0140e-02, -7.8902e-04,  8.4430e-03,  2.0605e-03,  1.0241e-02,\n",
      "         7.2320e-03,  6.5091e-03,  5.7597e-03,  2.8010e-03,  3.3997e-03,\n",
      "         1.9731e-02,  9.3175e-04,  7.6002e-03,  2.6399e-03, -6.9502e-04,\n",
      "        -2.8759e-02,  5.9514e-03,  1.0977e-03, -9.7836e-03,  3.5896e-03,\n",
      "        -2.2588e-02,  1.3205e-02, -1.1104e-02, -5.1183e-03,  1.1626e-02,\n",
      "        -1.7183e-02, -4.0211e-03, -1.0295e-02, -1.7413e-02])}, 140460888799920: {'momentum_buffer': tensor([[-2.1631e-03, -1.3824e-03,  2.3562e-04,  2.0777e-03,  1.8918e-03,\n",
      "          6.4295e-05,  6.8505e-05,  4.3750e-04, -1.0048e-03, -3.5702e-03,\n",
      "          2.1924e-05, -3.4598e-03, -2.9738e-03, -3.3690e-03,  1.0106e-07,\n",
      "          2.8989e-04, -1.7463e-03,  2.7500e-04, -4.0079e-04,  1.6820e-03,\n",
      "          1.0120e-03, -1.8696e-03,  7.1906e-05,  2.9426e-04, -9.3156e-04,\n",
      "          5.2358e-04, -1.2157e-03, -3.2046e-04, -1.5164e-03, -2.6686e-04,\n",
      "         -2.7976e-04, -4.3129e-04,  5.5637e-04,  8.0733e-06, -6.5709e-04,\n",
      "         -1.8172e-03, -2.5576e-03,  1.6986e-04, -1.4308e-03, -1.0186e-04,\n",
      "         -2.5184e-03, -3.5679e-03, -1.7313e-03,  6.0421e-04, -6.9922e-07,\n",
      "          4.6088e-04, -2.1824e-03, -6.8849e-04, -3.7976e-04, -2.5524e-03,\n",
      "         -2.2393e-03,  2.1620e-03,  6.7935e-04, -1.5815e-03,  4.4858e-06,\n",
      "          3.5890e-04,  3.6076e-05, -1.0794e-03,  7.3450e-05, -7.0184e-04,\n",
      "          2.3093e-04,  1.0665e-03,  7.0393e-04, -3.7991e-04],\n",
      "        [ 1.4132e-03,  3.7089e-03,  4.9661e-04,  2.5550e-03, -3.2752e-03,\n",
      "         -5.9567e-04, -1.3291e-03,  9.4574e-05,  1.4224e-02,  1.6435e-03,\n",
      "          2.9519e-03,  2.2514e-03,  1.7208e-04,  2.6263e-03, -3.0183e-03,\n",
      "          1.7853e-03,  1.5306e-03,  2.2359e-02,  4.3348e-04,  8.4818e-03,\n",
      "          8.0673e-04,  1.0441e-03,  1.0902e-02,  3.3762e-03,  5.4993e-03,\n",
      "         -3.6049e-03,  3.7506e-04, -6.4090e-03,  8.2711e-04, -1.0279e-03,\n",
      "         -2.8323e-03,  1.0464e-03,  2.6376e-03,  1.4275e-05,  1.8608e-02,\n",
      "          2.5213e-03,  1.6057e-03,  4.9259e-05,  1.5730e-05,  2.0509e-03,\n",
      "          1.9079e-03,  2.5334e-02, -1.1810e-03,  9.0112e-04, -9.3169e-05,\n",
      "          4.7411e-03,  2.5284e-03, -9.9572e-07,  2.0553e-02,  1.9031e-03,\n",
      "          5.1760e-03, -2.4318e-03,  8.6334e-03,  1.0714e-02,  1.2633e-02,\n",
      "          4.1878e-03,  3.2830e-03,  1.6651e-03,  1.2644e-03,  1.1215e-03,\n",
      "          6.5647e-03,  3.4506e-04,  1.9346e-03,  8.4736e-03],\n",
      "        [ 2.1126e-03,  1.3133e-02, -1.1135e-03,  9.3578e-03,  4.5293e-04,\n",
      "          2.0444e-04, -2.5845e-03, -3.1334e-04, -1.8288e-03,  1.2105e-02,\n",
      "          2.3498e-03, -7.2633e-04,  6.2286e-03,  5.0267e-03,  2.2798e-04,\n",
      "          2.3788e-03,  1.4905e-02,  1.1250e-02,  6.4276e-03,  2.2307e-02,\n",
      "          9.4749e-03,  6.2399e-03,  5.8822e-03,  1.2245e-02, -6.4597e-05,\n",
      "         -4.5963e-03,  3.2111e-04,  3.9916e-04,  4.2981e-03, -3.8761e-04,\n",
      "         -2.3045e-03, -1.6472e-03,  1.5630e-03,  5.6694e-06,  8.6473e-03,\n",
      "          9.5023e-03,  3.7554e-03,  1.8363e-04,  2.5693e-03,  1.4974e-02,\n",
      "          1.4018e-02,  1.5978e-02,  1.8289e-03,  4.3007e-03, -1.8189e-03,\n",
      "          5.6879e-03,  2.0199e-02,  1.7631e-02,  2.2155e-02,  1.1231e-03,\n",
      "          9.6652e-03,  7.8011e-03,  5.6818e-03,  6.1647e-03,  2.5804e-03,\n",
      "          2.4925e-02,  7.3445e-03,  2.9779e-02,  7.1553e-04,  8.9811e-04,\n",
      "          8.0769e-03,  5.8656e-03,  2.4001e-03,  6.0430e-03],\n",
      "        [ 1.0390e-03, -1.8623e-02,  9.5308e-03, -1.4690e-02, -2.9852e-02,\n",
      "         -2.6347e-03,  1.7244e-02,  1.4774e-02,  5.6051e-03, -1.1074e-02,\n",
      "         -1.1190e-02, -8.4447e-03, -6.3924e-03,  9.6328e-03, -6.4301e-04,\n",
      "         -1.6359e-02, -1.9660e-02,  3.2664e-02, -1.4048e-03,  1.7941e-02,\n",
      "          2.1716e-04, -3.0082e-02,  2.6817e-03, -3.2405e-03, -2.9199e-04,\n",
      "         -2.8258e-02,  1.3715e-02, -2.3309e-02, -7.8408e-03, -3.0074e-03,\n",
      "          3.4802e-03,  1.0880e-02,  2.1687e-03, -7.4770e-05,  6.9570e-03,\n",
      "         -2.5061e-03,  1.6588e-03, -1.2987e-02, -2.2077e-03, -2.0870e-02,\n",
      "         -4.0075e-03,  1.3380e-02, -1.5479e-02, -5.4209e-03, -1.2229e-04,\n",
      "         -1.5681e-03, -2.0149e-03, -7.2034e-04,  1.6072e-02,  1.2137e-03,\n",
      "          3.1996e-03, -2.8495e-02,  5.0084e-03,  2.1018e-02,  2.4756e-03,\n",
      "         -9.4827e-03, -1.0395e-03, -3.3795e-02,  4.7423e-03, -1.0166e-02,\n",
      "          1.5396e-03, -1.9429e-02,  1.1715e-03,  2.4063e-03],\n",
      "        [-5.3654e-03,  1.8815e-03, -8.7533e-03, -3.1816e-05, -2.1563e-02,\n",
      "         -2.9490e-02,  4.4054e-03, -9.0858e-03, -1.6505e-03, -7.8595e-03,\n",
      "         -3.1002e-02,  3.0843e-03, -5.9945e-03, -2.9369e-03,  1.8226e-03,\n",
      "          2.6072e-03, -1.0932e-02, -3.8178e-03, -6.1021e-03,  1.3669e-03,\n",
      "         -1.7014e-02,  1.3941e-03, -2.4942e-03, -1.0010e-02,  3.6716e-03,\n",
      "          1.1744e-02, -4.3196e-03, -3.4639e-02, -9.3718e-03, -3.0399e-03,\n",
      "          1.3029e-03, -5.0727e-03, -6.4918e-03,  1.0328e-07, -2.3537e-03,\n",
      "         -7.4642e-03, -1.4992e-03, -9.1803e-03, -7.9635e-04,  1.4353e-03,\n",
      "          3.9723e-04, -3.9106e-04, -2.9959e-02, -2.5514e-03,  9.9507e-05,\n",
      "          8.8809e-05, -1.4957e-04, -5.9535e-04, -7.7928e-04, -1.2632e-02,\n",
      "         -2.0218e-03,  1.3989e-03, -6.5090e-03, -2.5982e-04, -1.0576e-02,\n",
      "          2.8475e-05, -7.6289e-04,  1.5812e-03, -6.6849e-03, -9.3484e-03,\n",
      "         -1.9941e-02, -5.0206e-04, -3.1926e-02, -9.3609e-04],\n",
      "        [-5.4838e-03,  3.4506e-04, -9.9603e-03, -2.1363e-03, -4.9669e-03,\n",
      "         -2.9767e-03, -2.2370e-02, -1.4938e-02,  1.5850e-03,  2.8601e-03,\n",
      "          1.6919e-03,  1.0343e-03,  8.9112e-04, -1.5494e-02,  5.1973e-04,\n",
      "          3.7157e-03,  7.5114e-04, -3.2527e-02, -1.8646e-03, -2.2262e-02,\n",
      "          1.9589e-03, -1.6528e-02, -2.8237e-04, -5.3964e-04, -2.8898e-02,\n",
      "         -4.8609e-03, -1.9652e-02, -1.4362e-03, -1.3305e-03, -5.7291e-03,\n",
      "         -2.3918e-02, -1.1681e-02, -8.0813e-03,  9.2351e-05, -5.8342e-04,\n",
      "         -1.3361e-02, -3.5922e-02, -9.2293e-03, -6.1988e-04, -9.5204e-03,\n",
      "         -9.8591e-03, -1.2519e-02,  1.1922e-03, -1.9109e-03,  2.1016e-03,\n",
      "         -4.6624e-04,  1.2764e-03, -6.6940e-04, -3.6747e-02, -1.7036e-03,\n",
      "         -1.3965e-02,  2.4176e-03, -2.5705e-02, -3.1141e-02,  9.5246e-05,\n",
      "         -8.3578e-03, -2.6875e-03,  1.4989e-03, -1.8845e-02, -3.3911e-02,\n",
      "          1.1096e-03,  1.8692e-04,  2.5063e-03, -1.5779e-03],\n",
      "        [ 1.0074e-02,  8.8542e-04,  6.0576e-03,  4.5001e-03,  1.2791e-03,\n",
      "          1.4171e-03,  2.7878e-03,  5.8860e-03,  1.2306e-03,  3.5010e-03,\n",
      "          1.8501e-03,  3.9242e-03,  5.3265e-03,  7.6364e-03,  2.9074e-05,\n",
      "          2.2887e-03,  4.8123e-03,  7.2458e-03,  3.7192e-03,  3.8907e-03,\n",
      "          2.6352e-03,  2.5072e-03,  1.4618e-03,  4.8120e-03,  2.2348e-04,\n",
      "          4.4730e-04,  1.0111e-02,  3.4432e-03,  7.7101e-05,  1.5210e-03,\n",
      "          1.3950e-03,  6.4037e-03,  1.4818e-02, -2.2219e-05,  3.2600e-03,\n",
      "          1.8315e-03,  7.4916e-03,  5.3834e-04,  2.3376e-03,  9.6274e-04,\n",
      "          4.5837e-03,  4.8951e-03,  3.3616e-03,  3.1326e-03,  2.9873e-07,\n",
      "          4.6015e-04,  8.0301e-04,  1.3833e-03,  7.0733e-03,  9.6093e-03,\n",
      "          1.0371e-02,  6.9455e-04,  8.9735e-03,  1.1748e-02,  2.4237e-03,\n",
      "          4.7039e-03, -2.3251e-05,  5.9214e-04,  3.6112e-03,  1.1668e-03,\n",
      "          1.2059e-03,  1.6433e-03,  2.9419e-03,  2.3484e-03],\n",
      "        [ 1.0365e-03,  8.7958e-03,  3.2082e-03,  1.1209e-02,  2.5085e-02,\n",
      "          6.6686e-03,  4.9460e-03,  6.1757e-05,  1.1660e-02,  1.6578e-02,\n",
      "          1.3988e-02,  8.7534e-03, -5.7184e-04,  1.1237e-03,  2.1279e-03,\n",
      "          1.3887e-02,  1.6821e-03,  1.8021e-02, -4.1284e-04,  2.8600e-03,\n",
      "          1.2613e-03,  2.8375e-02,  1.4704e-03,  1.0319e-03,  4.4447e-02,\n",
      "          3.9978e-02,  8.5651e-04,  2.3089e-02,  2.2321e-02,  8.8925e-03,\n",
      "          1.9878e-02,  1.7506e-03,  3.0203e-04,  2.0994e-06,  8.6226e-04,\n",
      "          2.5096e-03,  2.0589e-02,  1.7806e-02,  1.1919e-04,  2.1600e-02,\n",
      "          9.6336e-04,  8.1474e-03,  1.3574e-02,  5.2721e-04,  3.9410e-05,\n",
      "          1.1348e-03,  5.4686e-03,  2.1732e-02,  1.7493e-02, -5.6312e-04,\n",
      "          8.7773e-04,  2.2899e-02,  1.0651e-02,  2.0029e-03,  3.8268e-03,\n",
      "          9.8931e-03,  8.0728e-04,  1.9818e-02,  1.8780e-02,  3.5921e-02,\n",
      "          7.0793e-04,  1.3243e-02,  2.7076e-04,  4.6044e-03],\n",
      "        [-2.8348e-03, -8.4155e-03, -3.0238e-03, -1.5448e-02, -6.8593e-04,\n",
      "          6.0738e-04, -7.4385e-03, -1.2830e-04, -3.0357e-02, -2.7885e-02,\n",
      "         -9.1267e-03,  9.0367e-04,  6.5211e-04, -5.6023e-03, -3.6168e-05,\n",
      "         -1.6791e-02,  1.9374e-03, -5.6767e-02, -7.2920e-03, -3.7010e-02,\n",
      "         -1.1204e-02, -1.7748e-03, -2.1228e-02, -1.6788e-02, -2.6103e-02,\n",
      "         -3.2093e-04, -1.2126e-04,  7.6867e-04, -1.4022e-02, -1.2901e-03,\n",
      "         -1.7476e-04, -2.7332e-03, -5.8384e-03, -3.0261e-05, -3.4886e-02,\n",
      "         -9.6022e-03, -1.1739e-04, -2.5310e-03,  4.8864e-04, -1.3381e-02,\n",
      "         -5.8128e-03, -5.0986e-02,  5.1226e-04, -1.3529e-03, -2.2242e-03,\n",
      "         -1.0562e-02, -2.6047e-02, -3.9698e-02, -4.7674e-02, -7.5535e-03,\n",
      "         -1.3622e-02, -8.5056e-03, -2.1393e-02, -2.2719e-02, -2.4261e-02,\n",
      "         -2.9980e-02, -6.9924e-03, -2.0277e-02, -1.6759e-02, -2.7431e-03,\n",
      "         -1.4073e-02, -3.8198e-03, -6.5054e-03, -2.1028e-02],\n",
      "        [ 1.7397e-04, -3.2709e-04,  3.3223e-03,  2.6052e-03,  3.1630e-02,\n",
      "          2.6736e-02,  4.2654e-03,  3.2121e-03,  5.4085e-04,  1.3705e-02,\n",
      "          2.8464e-02, -7.3192e-03,  2.6598e-03,  1.3652e-03, -1.0303e-03,\n",
      "          6.1962e-03,  6.7186e-03,  1.2969e-03,  6.8949e-03,  7.4400e-04,\n",
      "          1.0854e-02,  1.0691e-02,  1.5343e-03,  8.8189e-03,  2.4505e-03,\n",
      "         -1.1052e-02, -7.1475e-05,  3.8412e-02,  6.5601e-03,  4.3374e-03,\n",
      "          3.4537e-03,  1.4879e-03, -1.6326e-03,  6.5679e-06,  1.4776e-04,\n",
      "          1.8387e-02,  4.9990e-03,  1.5180e-02, -4.7559e-04,  2.8513e-03,\n",
      "          3.3201e-04, -2.6572e-04,  2.7880e-02,  1.7673e-03,  2.0145e-03,\n",
      "          2.3085e-05,  1.2048e-04,  1.6225e-03,  2.2353e-03,  1.1157e-02,\n",
      "          2.5549e-03,  2.0561e-03,  1.3981e-02,  4.0540e-03,  1.0800e-02,\n",
      "          3.7186e-03,  3.3789e-05,  2.1757e-04,  1.3102e-02,  1.7768e-02,\n",
      "          1.4575e-02,  1.3994e-03,  2.6499e-02,  4.4302e-05]])}, 140460888798264: {'momentum_buffer': tensor([-0.0017,  0.0058,  0.0175, -0.0064, -0.0116, -0.0110,  0.0073,  0.0114,\n",
      "        -0.0228,  0.0114])}}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 1e-06, 'nesterov': True, 'params': [140460888812928, 140460888730216, 140460888730072, 140460908412360, 140460892820392, 140460888797328, 140460888799920, 140460888798264]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8F7v0JlT8ZT"
   },
   "source": [
    "***Calculating Number of parameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Au8S3IPX_hN2",
    "outputId": "2ab5e575-099f-4fa1-963b-580ca39cc689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "242762"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDmds6CM_hI0"
   },
   "source": [
    "***Conclusion :***\n",
    "\n",
    "The model was built with combination of various parameters, using different optimizer functions, tuning the hyperparameters, for 1 and 2 hidden layers, for different batch sizes and for different values of epoch and the observations were recorded in an excel sheet for  and monitoring.\n",
    "\n",
    "There were two models that gave the best accuracy: <br>\n",
    "Model 1: **98.2%**<br>\n",
    "Architecture description:<br>\n",
    "1. Batch Size: 64<br>\n",
    "2. Learning rate: 0.001\n",
    "3. Number of parameters: 111146<br>\n",
    "4. Dropout: 0.2<br>\n",
    "5. Optimizer: Adam<br>\n",
    "6. Activation Function: ReLU<br>\n",
    "7. Input layer: 784<br>\n",
    "8. Hidden layer 1: 128<br>\n",
    "9. Hidden layer 2: 64<br>\n",
    "10. Output layer: 10<br>\n",
    "11. Number of epochs: 10<br>\n",
    "\n",
    "Model 2: **98.3%**<br>\n",
    "Architecture description:<br>\n",
    "1. Batch Size: 256<br>\n",
    "2. Learning rate: 0.001\n",
    "3. Number of parameters: 242762<br>\n",
    "4. Dropout: 0.2<br>\n",
    "5. Optimizer: SGD(lr=1e-2,decay=1e-6, momentum=0.9, nesterov=True)<br>\n",
    "6. Activation Function: ReLU<br>\n",
    "7. Input layer: 784<br>\n",
    "8. Hidden layer 1: 256<br>\n",
    "9. Hidden layer 2: 128<br>\n",
    "10. Output layer: 10<br>\n",
    "11. Number of epochs: 10<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL MNIST Assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
